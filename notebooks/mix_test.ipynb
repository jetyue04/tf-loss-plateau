{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YiF5Vq1LGhEw"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import yaml\n",
    "import argparse\n",
    "from dotmap import DotMap\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src\")  # make sure Python can find src/\n",
    "import data\n",
    "from model_linear import GPTLinear\n",
    "from model_softmax import GPTSoftmax\n",
    "# from train_step import train_step\n",
    "from multi_task_train import train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"src/configs/mix1_mws_mwp.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with open(\"src/configs/mix1_mws_mwp.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config = DotMap(config)\n",
    "config.model.vocab_size = max(config.data.p, config.data.max_num) + 1 # Vocabn of model\n",
    "config.model.block_size = 2 * config.data.num_tokens + 1 # Length of each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_task = len(config.data.tasks)\n",
    "data_samplers = {}\n",
    "for i in range(num_task):\n",
    "    task = config.data.tasks[i]\n",
    "    # print(config.data.tasks[i].name)\n",
    "    task_class = getattr(data, task.name)\n",
    "    data_samplers[task.name] = task_class(\n",
    "            min_num=config.data.min_num,\n",
    "        max_num=config.data.max_num,\n",
    "        k=config.data.k,\n",
    "        p=config.data.p,\n",
    "        sep = task.sep,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MovingWindowSum': <data.MovingWindowSum at 0x7f3b908c3580>,\n",
       " 'MovingWindowProduct': <data.MovingWindowProduct at 0x7f3b908c36a0>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2go74s5v) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mix_mws_mwp_linear_embeddingFrozen_TEST</strong> at: <a href='https://wandb.ai/wth_ucsd/loss_plateau_tf/runs/2go74s5v' target=\"_blank\">https://wandb.ai/wth_ucsd/loss_plateau_tf/runs/2go74s5v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251107_011850-2go74s5v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2go74s5v). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.22.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jyue/private/tf-loss-plateau/wandb/run-20251107_011904-mdozmuc3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wth_ucsd/loss_plateau_tf/runs/mdozmuc3' target=\"_blank\">mix_mws_mwp_linear_embeddingFrozen_TEST</a></strong> to <a href='https://wandb.ai/wth_ucsd/loss_plateau_tf' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wth_ucsd/loss_plateau_tf' target=\"_blank\">https://wandb.ai/wth_ucsd/loss_plateau_tf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wth_ucsd/loss_plateau_tf/runs/mdozmuc3' target=\"_blank\">https://wandb.ai/wth_ucsd/loss_plateau_tf/runs/mdozmuc3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 -- Train loss: 2.887983560562134, Train Acc: 0.062744140625 Test Acc: 0.0576171875\n",
      "Step 1 -- Train loss: 2.871685266494751, Train Acc: 0.05908203125 Test Acc: 0.0498046875\n",
      "Step 2 -- Train loss: 2.8500843048095703, Train Acc: 0.06640625 Test Acc: 0.064453125\n",
      "Step 3 -- Train loss: 2.8298401832580566, Train Acc: 0.0654296875 Test Acc: 0.0537109375\n",
      "Step 4 -- Train loss: 2.819368839263916, Train Acc: 0.06005859375 Test Acc: 0.0576171875\n",
      "Step 5 -- Train loss: 2.8032753467559814, Train Acc: 0.058349609375 Test Acc: 0.05859375\n",
      "Step 6 -- Train loss: 2.7883567810058594, Train Acc: 0.065185546875 Test Acc: 0.06640625\n",
      "Step 7 -- Train loss: 2.7779343128204346, Train Acc: 0.064208984375 Test Acc: 0.0537109375\n",
      "Step 8 -- Train loss: 2.774282217025757, Train Acc: 0.064453125 Test Acc: 0.0625\n",
      "Step 9 -- Train loss: 2.7677390575408936, Train Acc: 0.063232421875 Test Acc: 0.0712890625\n",
      "Step 10 -- Train loss: 2.762723207473755, Train Acc: 0.065185546875 Test Acc: 0.0634765625\n",
      "Step 11 -- Train loss: 2.7612528800964355, Train Acc: 0.0546875 Test Acc: 0.0478515625\n",
      "Step 12 -- Train loss: 2.766216993331909, Train Acc: 0.0634765625 Test Acc: 0.0634765625\n",
      "Step 13 -- Train loss: 2.7547333240509033, Train Acc: 0.0615234375 Test Acc: 0.064453125\n",
      "Step 14 -- Train loss: 2.754706382751465, Train Acc: 0.058349609375 Test Acc: 0.0732421875\n",
      "Step 15 -- Train loss: 2.752302885055542, Train Acc: 0.0732421875 Test Acc: 0.068359375\n",
      "Step 16 -- Train loss: 2.7529468536376953, Train Acc: 0.0654296875 Test Acc: 0.048828125\n",
      "Step 17 -- Train loss: 2.752443552017212, Train Acc: 0.061767578125 Test Acc: 0.05859375\n",
      "Step 18 -- Train loss: 2.749805212020874, Train Acc: 0.06787109375 Test Acc: 0.0771484375\n",
      "Step 19 -- Train loss: 2.754085063934326, Train Acc: 0.072509765625 Test Acc: 0.060546875\n",
      "Step 20 -- Train loss: 2.7513654232025146, Train Acc: 0.064208984375 Test Acc: 0.0625\n",
      "Step 21 -- Train loss: 2.748283863067627, Train Acc: 0.0595703125 Test Acc: 0.048828125\n",
      "Step 22 -- Train loss: 2.750610589981079, Train Acc: 0.0556640625 Test Acc: 0.0693359375\n",
      "Step 23 -- Train loss: 2.7478103637695312, Train Acc: 0.060546875 Test Acc: 0.0595703125\n",
      "Step 24 -- Train loss: 2.743262529373169, Train Acc: 0.068359375 Test Acc: 0.06640625\n",
      "Step 25 -- Train loss: 2.75008225440979, Train Acc: 0.063720703125 Test Acc: 0.060546875\n",
      "Step 26 -- Train loss: 2.745511293411255, Train Acc: 0.057373046875 Test Acc: 0.0537109375\n",
      "Step 27 -- Train loss: 2.7441036701202393, Train Acc: 0.0576171875 Test Acc: 0.0732421875\n",
      "Step 28 -- Train loss: 2.744342565536499, Train Acc: 0.0712890625 Test Acc: 0.0634765625\n",
      "Step 29 -- Train loss: 2.7453501224517822, Train Acc: 0.060546875 Test Acc: 0.0595703125\n",
      "Step 30 -- Train loss: 2.745671033859253, Train Acc: 0.062744140625 Test Acc: 0.060546875\n",
      "Step 31 -- Train loss: 2.743597984313965, Train Acc: 0.058349609375 Test Acc: 0.0556640625\n",
      "Step 32 -- Train loss: 2.745331287384033, Train Acc: 0.07080078125 Test Acc: 0.0654296875\n",
      "Step 33 -- Train loss: 2.7414422035217285, Train Acc: 0.063232421875 Test Acc: 0.0595703125\n",
      "Step 34 -- Train loss: 2.74247407913208, Train Acc: 0.065185546875 Test Acc: 0.060546875\n",
      "Step 35 -- Train loss: 2.7422757148742676, Train Acc: 0.06201171875 Test Acc: 0.0517578125\n",
      "Step 36 -- Train loss: 2.7422940731048584, Train Acc: 0.0673828125 Test Acc: 0.0576171875\n",
      "Step 37 -- Train loss: 2.742048740386963, Train Acc: 0.05810546875 Test Acc: 0.06640625\n",
      "Step 38 -- Train loss: 2.73993182182312, Train Acc: 0.060302734375 Test Acc: 0.0810546875\n",
      "Step 39 -- Train loss: 2.7398321628570557, Train Acc: 0.052734375 Test Acc: 0.0576171875\n",
      "Step 40 -- Train loss: 2.742438316345215, Train Acc: 0.059326171875 Test Acc: 0.05859375\n",
      "Step 41 -- Train loss: 2.7404727935791016, Train Acc: 0.06689453125 Test Acc: 0.0791015625\n",
      "Step 42 -- Train loss: 2.738112211227417, Train Acc: 0.062744140625 Test Acc: 0.05859375\n",
      "Step 43 -- Train loss: 2.7399468421936035, Train Acc: 0.064208984375 Test Acc: 0.0615234375\n",
      "Step 44 -- Train loss: 2.7410268783569336, Train Acc: 0.06005859375 Test Acc: 0.0634765625\n",
      "Step 45 -- Train loss: 2.738107204437256, Train Acc: 0.072265625 Test Acc: 0.0595703125\n",
      "Step 46 -- Train loss: 2.7395336627960205, Train Acc: 0.06103515625 Test Acc: 0.0478515625\n",
      "Step 47 -- Train loss: 2.739185094833374, Train Acc: 0.06396484375 Test Acc: 0.0634765625\n",
      "Step 48 -- Train loss: 2.7388830184936523, Train Acc: 0.061767578125 Test Acc: 0.064453125\n",
      "Step 49 -- Train loss: 2.738297700881958, Train Acc: 0.06005859375 Test Acc: 0.0703125\n",
      "Step 50 -- Train loss: 2.7385337352752686, Train Acc: 0.063720703125 Test Acc: 0.0634765625\n",
      "Step 51 -- Train loss: 2.734697103500366, Train Acc: 0.066650390625 Test Acc: 0.0576171875\n",
      "Step 52 -- Train loss: 2.736049175262451, Train Acc: 0.0751953125 Test Acc: 0.0732421875\n",
      "Step 53 -- Train loss: 2.735090970993042, Train Acc: 0.072509765625 Test Acc: 0.05859375\n",
      "Step 54 -- Train loss: 2.733720302581787, Train Acc: 0.07080078125 Test Acc: 0.0771484375\n",
      "Step 55 -- Train loss: 2.7370076179504395, Train Acc: 0.070556640625 Test Acc: 0.0654296875\n",
      "Step 56 -- Train loss: 2.734825611114502, Train Acc: 0.078857421875 Test Acc: 0.0703125\n",
      "Step 57 -- Train loss: 2.7318387031555176, Train Acc: 0.071533203125 Test Acc: 0.076171875\n",
      "Step 58 -- Train loss: 2.731187105178833, Train Acc: 0.07421875 Test Acc: 0.0712890625\n",
      "Step 59 -- Train loss: 2.7330009937286377, Train Acc: 0.073974609375 Test Acc: 0.0673828125\n",
      "Step 60 -- Train loss: 2.7333450317382812, Train Acc: 0.0634765625 Test Acc: 0.060546875\n",
      "Step 61 -- Train loss: 2.734349489212036, Train Acc: 0.060302734375 Test Acc: 0.05859375\n",
      "Step 62 -- Train loss: 2.7333083152770996, Train Acc: 0.063720703125 Test Acc: 0.07421875\n",
      "Step 63 -- Train loss: 2.7305665016174316, Train Acc: 0.063232421875 Test Acc: 0.064453125\n",
      "Step 64 -- Train loss: 2.730167865753174, Train Acc: 0.06689453125 Test Acc: 0.072265625\n",
      "Step 65 -- Train loss: 2.7286911010742188, Train Acc: 0.070068359375 Test Acc: 0.0771484375\n",
      "Step 66 -- Train loss: 2.7291877269744873, Train Acc: 0.08154296875 Test Acc: 0.0751953125\n",
      "Step 67 -- Train loss: 2.730489730834961, Train Acc: 0.075439453125 Test Acc: 0.0654296875\n",
      "Step 68 -- Train loss: 2.726933002471924, Train Acc: 0.0712890625 Test Acc: 0.0751953125\n",
      "Step 69 -- Train loss: 2.7262518405914307, Train Acc: 0.083984375 Test Acc: 0.0673828125\n",
      "Step 70 -- Train loss: 2.72532057762146, Train Acc: 0.080322265625 Test Acc: 0.0654296875\n",
      "Step 71 -- Train loss: 2.723062038421631, Train Acc: 0.0791015625 Test Acc: 0.0810546875\n",
      "Step 72 -- Train loss: 2.725400686264038, Train Acc: 0.079345703125 Test Acc: 0.0908203125\n",
      "Step 73 -- Train loss: 2.722153902053833, Train Acc: 0.080322265625 Test Acc: 0.0810546875\n",
      "Step 74 -- Train loss: 2.7239859104156494, Train Acc: 0.080078125 Test Acc: 0.087890625\n",
      "Step 75 -- Train loss: 2.723381519317627, Train Acc: 0.086669921875 Test Acc: 0.0947265625\n",
      "Step 76 -- Train loss: 2.7177131175994873, Train Acc: 0.08251953125 Test Acc: 0.09765625\n",
      "Step 77 -- Train loss: 2.721482038497925, Train Acc: 0.0869140625 Test Acc: 0.0947265625\n",
      "Step 78 -- Train loss: 2.71840500831604, Train Acc: 0.097900390625 Test Acc: 0.103515625\n",
      "Step 79 -- Train loss: 2.7179484367370605, Train Acc: 0.1083984375 Test Acc: 0.103515625\n",
      "Step 80 -- Train loss: 2.7164571285247803, Train Acc: 0.098388671875 Test Acc: 0.107421875\n",
      "Step 81 -- Train loss: 2.7126047611236572, Train Acc: 0.099853515625 Test Acc: 0.1044921875\n",
      "Step 82 -- Train loss: 2.7081589698791504, Train Acc: 0.109619140625 Test Acc: 0.1064453125\n",
      "Step 83 -- Train loss: 2.7085933685302734, Train Acc: 0.107666015625 Test Acc: 0.11328125\n",
      "Step 84 -- Train loss: 2.704414129257202, Train Acc: 0.102783203125 Test Acc: 0.111328125\n",
      "Step 85 -- Train loss: 2.6996092796325684, Train Acc: 0.1083984375 Test Acc: 0.1044921875\n",
      "Step 86 -- Train loss: 2.6946401596069336, Train Acc: 0.112060546875 Test Acc: 0.1123046875\n",
      "Step 87 -- Train loss: 2.6925995349884033, Train Acc: 0.111572265625 Test Acc: 0.0947265625\n",
      "Step 88 -- Train loss: 2.685667037963867, Train Acc: 0.109130859375 Test Acc: 0.1201171875\n",
      "Step 89 -- Train loss: 2.6829328536987305, Train Acc: 0.1171875 Test Acc: 0.1142578125\n",
      "Step 90 -- Train loss: 2.682762384414673, Train Acc: 0.112548828125 Test Acc: 0.12109375\n",
      "Step 91 -- Train loss: 2.6788907051086426, Train Acc: 0.112548828125 Test Acc: 0.1162109375\n",
      "Step 92 -- Train loss: 2.676284074783325, Train Acc: 0.11865234375 Test Acc: 0.1201171875\n",
      "Step 93 -- Train loss: 2.672102928161621, Train Acc: 0.118896484375 Test Acc: 0.107421875\n",
      "Step 94 -- Train loss: 2.670734405517578, Train Acc: 0.119140625 Test Acc: 0.115234375\n",
      "Step 95 -- Train loss: 2.666705846786499, Train Acc: 0.11962890625 Test Acc: 0.1318359375\n",
      "Step 96 -- Train loss: 2.6646792888641357, Train Acc: 0.11962890625 Test Acc: 0.1201171875\n",
      "Step 97 -- Train loss: 2.6631834506988525, Train Acc: 0.12158203125 Test Acc: 0.1298828125\n",
      "Step 98 -- Train loss: 2.6632068157196045, Train Acc: 0.131591796875 Test Acc: 0.111328125\n",
      "Step 99 -- Train loss: 2.658007860183716, Train Acc: 0.110595703125 Test Acc: 0.1298828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>att_prog_measure</td><td>▅▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▂▂▂▂▃▄▄▅▆▇▇█</td></tr><tr><td>data_repeat_frac</td><td>▆▃▄▆▄▄▂▄▆▄▃▅▃▅▂▄▄▁▆▅▅▅▄▅▃▄▇▄▄▄▅▅▇█▄▅▄▃▅▃</td></tr><tr><td>idx0_check</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▂▂▂▂▃▂▃▄▄▅▆▇▇▇▇███</td></tr><tr><td>idx10_check</td><td>▄▃▁▅▄▃▆▆▅▄▇▃▆▅▄█▆▃▅▃▅▁▇█▆▄▄▄▄▅▃▃▅▄▃▆▄▅▆▃</td></tr><tr><td>idx11_check</td><td>▄▆▃▄▆▃▅▂▄▄▄▃▃▃▂▃▃▄▃▃▅▅▃▅▄▄█▅▃▁▁▅▃▃▄▂▅▂▃▄</td></tr><tr><td>idx12_check</td><td>▃▄▆▃▆▄█▆▅▂▃▂▄▁▃▂▂▄▄▇▆▆▅▅▆▅▄▃▆▄▃▅▇▄▄█▄▇▄▄</td></tr><tr><td>idx13_check</td><td>▄▇▄▆▄▆▄▅▇▅▅▂▇▃▄▅▅▇▇▇▂▄▅▅▁▂▅▂▅▄█▆▄▄▇▃▅▇▇▅</td></tr><tr><td>idx14_check</td><td>▃▅▅▅▇▆▆▃▃▇▅▃▅▄▁▃▄▅▅▃▃▅▁▃▅▅▅▇▁▃▆▅▅▆▅▃█▄▃▃</td></tr><tr><td>idx15_check</td><td>█▅▆▄▃▄▆▆▆▆▅▄▇▂▇▄▄▄▇▅▇▇▅▄▅▂█▂▃▃▂▆▅▃▆▆▃▁▄▆</td></tr><tr><td>idx1_check</td><td>▆▂▃▃▁▆▄▆▅▃▅▇▁▆▅▂▃▃▆▄▄█▆▃▁▃▄▃▆▂▂▅▅▅▅▂██▃▃</td></tr><tr><td>idx2_check</td><td>▄▄▅▃▅▅▃▅▃▂▅▄▅▄▃▄▄▄█▄▄▃▃▄▅▁▅▆▁▅▅▅▅▄▄▄▄▅▃▄</td></tr><tr><td>idx3_check</td><td>▂▂▃▄▃▄▅▄▄▂▄▃▃▃▃▃▃▁▅▃▃▃▃▃▃▃▄▄█▄▃▁▃▃▄▄▃▃▆▁</td></tr><tr><td>idx4_check</td><td>▄▆▅█▃▂▄▄▅▁▃▅▃▃▆▅▄▇▅▄▄█▄▄▂▅██▅▅▄▁▃▄▅▆▃▄▅▃</td></tr><tr><td>idx5_check</td><td>▄▅▆▄▄▇▄▄▅▄▄▅▃▅▂▆▆▆▅▃▂▄▅▅▃▃▂▃▅█▄▄▃▄▂▂▅▅▅▁</td></tr><tr><td>idx6_check</td><td>▆█▃▆▆▅▇▂▅▆▆▄▃▅▅▄▆▆▃▆▆▅▇▆▂▃▅▂▅▁▆▇▃▅▇▅▄▅▅▅</td></tr><tr><td>idx7_check</td><td>▆▄▅▇▇▆▇▃▅▆▁▅▄▃▂▅▃▃▅▃▂▅▇█▃▆▃▆▃▁▂▃▃▁▃▁▃▃▅▂</td></tr><tr><td>idx8_check</td><td>▅▄▂▆▅▁▇▁▅▁▇▄▂▅█▃▇▅▃▄▄▂▇▇▅▂▆▅▄▁▆▆▅▂▅▇▆▄▅▅</td></tr><tr><td>idx9_check</td><td>▂▇▃▄▄▆▅▅▄▂▄▂▇▆█▅▄▅▇▁▅▅▂▅▂▃▅▃▃█▁█▇█▂▄▃▆▁▂</td></tr><tr><td>mean_cosine_sim</td><td>▁▁▂▂▄▅▆▆▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>mean_cosine_sim_0</td><td>▂▂▂▄▅▆▇█████████▇▇▇▇▇▇▇▆▆▆▅▅▄▅▄▄▃▄▃▃▃▁▁▂</td></tr><tr><td>mean_cosine_sim_1</td><td>▁▁▂▂▄▅▆▇▇▇▇▇▇▇███▇██████████████████████</td></tr><tr><td>mean_cosine_sim_10</td><td>▁▁▂▂▄▅▆▆▆▆▇▇▇▇██████████████████████████</td></tr><tr><td>mean_cosine_sim_11</td><td>▁▁▂▂▄▅▆▆▆▇▇▇▇▇██████████████████████████</td></tr><tr><td>mean_cosine_sim_12</td><td>▁▁▁▂▄▅▆▆▆▆▇▇▇▇▇▇████████████████████████</td></tr><tr><td>mean_cosine_sim_13</td><td>▁▁▂▃▅▅▆▆▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>mean_cosine_sim_14</td><td>▁▁▂▃▄▅▆▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>mean_cosine_sim_2</td><td>▁▁▁▂▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>mean_cosine_sim_3</td><td>▁▁▂▃▄▅▆▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>mean_cosine_sim_4</td><td>▁▁▂▃▄▅▆▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>mean_cosine_sim_5</td><td>▁▁▁▁▃▄▆▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>mean_cosine_sim_6</td><td>▁▁▂▃▅▆▆▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>mean_cosine_sim_7</td><td>▁▁▂▃▄▅▆▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>mean_cosine_sim_8</td><td>▁▁▂▃▄▅▆▆▇▇▇▇▇███████████████████████████</td></tr><tr><td>mean_cosine_sim_9</td><td>▁▁▂▃▄▅▆▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>model_repeat_frac</td><td>▁▁▂▂▂▃▂▄█▄▃▂▃▅▇▄▅▅▇▅▇▅▄█▇▃▃▃▅▅▄▂▂▁▆▆▁▁▂▂</td></tr><tr><td>test_acc</td><td>▂▂▂▁▂▂▂▂▂▃▂▃▂▂▁▄▂▂▂▂▂▂▂▃▂▂▃▃▄▄▅▆▆▇▆▇▇▆▇█</td></tr><tr><td>train_acc</td><td>▂▂▁▂▂▂▃▂▂▁▂▁▂▂▂▂▁▂▃▂▂▃▃▃▂▂▄▃▄▄▄▆▆▇▇▇▇██▇</td></tr><tr><td>train_loss</td><td>█▇▅▅▄▄▄▄▄▄▄▄▄▄▄▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>att_prog_measure</td><td>0.08647</td></tr><tr><td>data_repeat_frac</td><td>0.05208</td></tr><tr><td>idx0_check</td><td>1.0</td></tr><tr><td>idx10_check</td><td>0.04688</td></tr><tr><td>idx11_check</td><td>0.05859</td></tr><tr><td>idx12_check</td><td>0.05469</td></tr><tr><td>idx13_check</td><td>0.05469</td></tr><tr><td>idx14_check</td><td>0.04688</td></tr><tr><td>idx15_check</td><td>0.07812</td></tr><tr><td>idx1_check</td><td>0.05469</td></tr><tr><td>idx2_check</td><td>0.05469</td></tr><tr><td>idx3_check</td><td>0.03125</td></tr><tr><td>idx4_check</td><td>0.04688</td></tr><tr><td>idx5_check</td><td>0.03906</td></tr><tr><td>idx6_check</td><td>0.05859</td></tr><tr><td>idx7_check</td><td>0.04688</td></tr><tr><td>idx8_check</td><td>0.05859</td></tr><tr><td>idx9_check</td><td>0.03906</td></tr><tr><td>mean_cosine_sim</td><td>0.9551</td></tr><tr><td>mean_cosine_sim_0</td><td>0.06947</td></tr><tr><td>mean_cosine_sim_1</td><td>0.92238</td></tr><tr><td>mean_cosine_sim_10</td><td>0.96868</td></tr><tr><td>mean_cosine_sim_11</td><td>0.96737</td></tr><tr><td>mean_cosine_sim_12</td><td>0.96549</td></tr><tr><td>mean_cosine_sim_13</td><td>0.96545</td></tr><tr><td>mean_cosine_sim_14</td><td>0.97069</td></tr><tr><td>mean_cosine_sim_2</td><td>0.94272</td></tr><tr><td>mean_cosine_sim_3</td><td>0.95729</td></tr><tr><td>mean_cosine_sim_4</td><td>0.95823</td></tr><tr><td>mean_cosine_sim_5</td><td>0.96055</td></tr><tr><td>mean_cosine_sim_6</td><td>0.96612</td></tr><tr><td>mean_cosine_sim_7</td><td>0.96291</td></tr><tr><td>mean_cosine_sim_8</td><td>0.96537</td></tr><tr><td>mean_cosine_sim_9</td><td>0.96946</td></tr><tr><td>model_repeat_frac</td><td>0.09792</td></tr><tr><td>test_acc</td><td>0.12988</td></tr><tr><td>train_acc</td><td>0.1106</td></tr><tr><td>train_loss</td><td>2.65801</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mix_mws_mwp_linear_embeddingFrozen_TEST</strong> at: <a href='https://wandb.ai/wth_ucsd/loss_plateau_tf/runs/mdozmuc3' target=\"_blank\">https://wandb.ai/wth_ucsd/loss_plateau_tf/runs/mdozmuc3</a><br/>Synced 6 W&B file(s), 100 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251107_011904-mdozmuc3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## initialize model\n",
    "if config.model.linear:\n",
    "    model = GPTLinear(config.model, return_att=True).to(device)\n",
    "else:\n",
    "    model = GPTSoftmax(config.model, return_att=True).to(device)\n",
    "\n",
    "optim = Adam(model.parameters(), lr=config.train.lr)\n",
    "\n",
    "if config.train.wandb:\n",
    "    wandb_run_name = config.train.wandb_run_name\n",
    "    wandb.login(key=\"\")\n",
    "    wandb.init(project=config.train.wandb_project, name=wandb_run_name, config=config)\n",
    "    wandb.watch(model)\n",
    "\n",
    "for step in range(config.train.num_steps):\n",
    "    train_step(\n",
    "        model=model,\n",
    "        optim=optim,\n",
    "        data_samplers=data_samplers,\n",
    "        step=step,\n",
    "        config=config,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "if config.train.wandb:\n",
    "    wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
